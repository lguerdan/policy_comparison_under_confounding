{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "903a0e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from bound_funcs import *\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return e_x / np.sum(e_x, axis=1, keepdims=True)\n",
    "\n",
    "def generate_positive_semidefinite_matrix(dim, seed=None):\n",
    "    \"\"\"\n",
    "    Generates a random positive semidefinite matrix.\n",
    "    \n",
    "    Parameters:\n",
    "        dim (int): The dimension of the square matrix.\n",
    "        seed (int, optional): A seed for the random number generator to make results reproducible.\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: A dim x dim positive semidefinite matrix.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    # Generate a random matrix A\n",
    "    A = np.random.randn(dim, dim)\n",
    "    \n",
    "    # Multiply A by its transpose to get a symmetric and positive semidefinite matrix\n",
    "    matrix = np.dot(A, A.T)\n",
    "    \n",
    "    # Adding a small value to the diagonal elements to ensure the matrix is positive definite\n",
    "    matrix += np.eye(dim) * 1e-8\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "def check_p_bounds(data):\n",
    "    '''Given observational data (Y,D,T) ~ p() compute bounds across measures of interest.'''\n",
    "    \n",
    "    Y, D, T = data['Y'], data['D'], data['T']\n",
    "    Vpf_down = np.zeros((2,2))\n",
    "    Vpf_up = np.zeros((2,2))\n",
    "    v = np.zeros((2,2,2))\n",
    "\n",
    "    for y in range(2):\n",
    "        for d in range(2):\n",
    "            for t in range(2):\n",
    "                v[y,t,d] = ((Y==y) & (D==d) & (T==t)).mean()\n",
    "\n",
    "\n",
    "    Vpf_up[0,1] = ((D==0) & (T==1)).mean()\n",
    "    Vpf_up[1,1] = ((D==0) & (T==1)).mean()\n",
    "    Vpf_up[0,0] = ((D==0) & (T==0)).mean()\n",
    "    Vpf_up[1,0] = ((D==0) & (T==0)).mean()\n",
    "    \n",
    "    metrics = ['m_y=1', 'm_y=0', 'm_a=0', 'm_a=1', 'm_u']\n",
    "    u = np.array([[1,0], [0, 1]])\n",
    "\n",
    "    for metric in metrics:\n",
    "        R_oracle = oracle_regret(v, u, metric)\n",
    "\n",
    "        Rs_down, Rs_up = standard_bounds(v, Vpf_down, Vpf_up, u, metric)\n",
    "        Rd_down, Rd_up = delta_bounds(v, Vpf_down, Vpf_up, u, metric)\n",
    "\n",
    "        print(f'metric: {metric}')\n",
    "        print(f'Standard bounds [{Rs_down:.3}, {Rs_up:.3}]')\n",
    "        print(f'Delta bounds: [{Rd_down:.3}, {Rd_up:.3}]')\n",
    "        print(f'Oracle: {R_oracle:.4}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "id": "70b61153",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "nDx = 3\n",
    "nDu = 10\n",
    "nD = Dx+Du\n",
    "norm = 1/(2*np.sqrt(nD))\n",
    "\n",
    "T = np.random.binomial(1,.35*np.ones(N))\n",
    "\n",
    "dgp_assumption = 'IV'\n",
    "\n",
    "\n",
    "# Instrument parameters\n",
    "nz = 5             # Number of finite values\n",
    "nw = 5\n",
    "beta_zd = 2        # Z -> D loading (=0 ==> relevance is violated)\n",
    "beta_zy = 0        # Z -> Y loading (=0 ==> exclusion restriction is satisfied)\n",
    "\n",
    "\n",
    "# Sample measured and unmeasured confounders\n",
    "mu, sigma = np.zeros(nD), np.eye(nD)\n",
    "XU = np.random.multivariate_normal(mu, sigma, N)\n",
    "\n",
    "# Measured and unmeasured covariate loadings\n",
    "e1_coeffs = 2*np.random.rand(nD) - 1\n",
    "z_coeffs = 2*np.random.rand(nD) - 1\n",
    "w_coeffs = 2*np.random.rand(nD) - 1\n",
    "mu1_coeffs = 2*np.random.rand(nD) - 1\n",
    "mu0_coeffs = 2*np.random.rand(nD) - 1\n",
    "\n",
    "# Zero out these terms if the IV unconfoundedness assumption is satisfied\n",
    "if dgp_assumption == 'IV':\n",
    "    z_coeffs[Du:] = 0\n",
    "\n",
    "# Compute the probability distribution for Z\n",
    "prob_Z = np.exp(z_coeffs*XU)\n",
    "prob_Z = prob_Z / np.sum(prob_Z.sum(axis=1))  \n",
    "weights = np.random.rand(nD, nz)\n",
    "logits = np.dot(XU, weights)\n",
    "pZ = softmax(logits)\n",
    "\n",
    "# Sample instrument values\n",
    "Z = np.argmax(np.array([np.random.multinomial(1, p) for p in pZ]), axis=1)\n",
    "\n",
    "# Treatment propensity is a function of X, U and Z. Beta is a scaling factor.\n",
    "pD = sigmoid(norm * ((e1_coeffs * XU).sum(axis=1) + beta_zd * Z))\n",
    "D = np.random.binomial(1, pD)\n",
    "\n",
    "\n",
    "# Compute the probability distribution for W\n",
    "# prob_W = np.exp(w_coeffs*XU)\n",
    "# prob_W = prob_W / np.sum(prob_W.sum(axis=1))  \n",
    "# weights = np.random.rand(nD, nW)\n",
    "# logits = np.dot(XU, weights)\n",
    "# pW = softmax(logits)\n",
    "# W = np.argmax(np.array([np.random.multinomial(1, p) for p in pW]), axis=1)\n",
    "\n",
    "p_mu_1 = sigmoid(norm * ((mu1_coeffs * XU).sum(axis=1) + beta_zy*Z))\n",
    "p_mu_0 = sigmoid(norm * ((mu0_coeffs * XU).sum(axis=1) + beta_zy*Z))\n",
    "p_mu = pD*p_mu_1 + (1-pD)*p_mu_0\n",
    "\n",
    "Y = np.random.binomial(1, p_mu)\n",
    "\n",
    "\n",
    "data = {\n",
    "    'Y': Y,\n",
    "    'D': D,\n",
    "    'X': X,\n",
    "    'Z': Z\n",
    "}\n",
    "\n",
    "# return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "id": "f35ff685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for z in range(nz):\n",
    "    plt.hist(pD[Z==z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "id": "c3491ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric: m_y=1\n",
      "Standard bounds [-0.544, -0.0862]\n",
      "Delta bounds: [-0.455, -0.186]\n",
      "Oracle: -0.2884\n",
      "\n",
      "metric: m_y=0\n",
      "Standard bounds [-0.558, -0.0978]\n",
      "Delta bounds: [-0.473, -0.195]\n",
      "Oracle: -0.3\n",
      "\n",
      "metric: m_a=0\n",
      "Standard bounds [-0.372, 0.393]\n",
      "Delta bounds: [-0.172, 0.193]\n",
      "Oracle: 0.003315\n",
      "\n",
      "metric: m_a=1\n",
      "Standard bounds [-0.0934, 0.106]\n",
      "Delta bounds: [-0.0934, 0.106]\n",
      "Oracle: 0.00942\n",
      "\n",
      "metric: m_u\n",
      "Standard bounds [-0.196, 0.204]\n",
      "Delta bounds: [-0.066, 0.0744]\n",
      "Oracle: 0.0038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mu_down_z = np.zeros((nz, N))\n",
    "mu_up_z = np.zeros((nz, N))\n",
    "\n",
    "# Compute upper and lower bounds on mu(a,x)\n",
    "for z in range(nz):\n",
    "    e1_z = sigmoid(norm * ((e1_coeffs * XU).sum(axis=1) + beta_zd * z))\n",
    "    e0_z = 1-e1_z\n",
    "\n",
    "    mu_down_z[z] = e1_z*p_mu_1\n",
    "    mu_up_z[z] = e0_z + e1_z*p_mu_1\n",
    "\n",
    "mu_down = mu_down_z.max(axis=0)\n",
    "mu_up = mu_up_z.min(axis=0)\n",
    "\n",
    "e1 = sigmoid(norm * ((e1_coeffs * XU).sum(axis=1) + beta_zd * Z))\n",
    "\n",
    "v110_up = (T * (mu_up - p_mu_1 * e1)).mean()\n",
    "v100_up = ((1-T) * (mu_up - p_mu_1 * e1)).mean()\n",
    "\n",
    "v110_down = (T * (mu_down - p_mu_1 * e1)).mean()\n",
    "v100_down = ((1-T) * (mu_down - p_mu_1 * e1)).mean()\n",
    "\n",
    "    \n",
    "\n",
    "Vpf_down = np.zeros((2,2))\n",
    "Vpf_up = np.zeros((2,2))\n",
    "v = np.zeros((2,2,2))\n",
    "\n",
    "for y in range(2):\n",
    "    for d in range(2):\n",
    "        for t in range(2):\n",
    "            v[y,t,d] = ((Y==y) & (D==d) & (T==t)).mean()\n",
    "\n",
    "\n",
    "Vpf_up[0,1] = v110_up\n",
    "Vpf_up[1,1] = v110_up\n",
    "Vpf_up[0,0] = v100_up\n",
    "Vpf_up[1,0] = v100_up            \n",
    "\n",
    "Vpf_down[0,1] = v110_down\n",
    "Vpf_down[1,1] = v110_down\n",
    "Vpf_down[0,0] = v100_down\n",
    "Vpf_down[1,0] = v100_down\n",
    "\n",
    "\n",
    "    \n",
    "metrics = ['m_y=1', 'm_y=0', 'm_a=0', 'm_a=1', 'm_u']\n",
    "u = np.array([[1,0], [0, 1]])\n",
    "\n",
    "for metric in metrics:\n",
    "    R_oracle = oracle_regret(v, u, metric)\n",
    "\n",
    "    Rs_down, Rs_up = standard_bounds(v, Vpf_down, Vpf_up, u, metric)\n",
    "    Rd_down, Rd_up = delta_bounds(v, Vpf_down, Vpf_up, u, metric)\n",
    "\n",
    "    print(f'metric: {metric}')\n",
    "    print(f'Standard bounds [{Rs_down:.3}, {Rs_up:.3}]')\n",
    "    print(f'Delta bounds: [{Rd_down:.3}, {Rd_up:.3}]')\n",
    "    print(f'Oracle: {R_oracle:.4}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99be303b",
   "metadata": {},
   "source": [
    "## Now, given these nuisance functions, we'd like to estimate Vpf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19d8505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b68a70a8",
   "metadata": {},
   "source": [
    "## Test computing bounds from the sampled joint distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "03acaf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric: m_y=1\n",
      "Standard bounds [-0.653, 0.177]\n",
      "Delta bounds: [-0.494, 0.0182]\n",
      "Oracle: -0.1591\n",
      "\n",
      "metric: m_y=0\n",
      "Standard bounds [-0.691, 0.143]\n",
      "Delta bounds: [-0.55, -0.0126]\n",
      "Oracle: -0.186\n",
      "\n",
      "metric: m_a=0\n",
      "Standard bounds [-0.641, 0.672]\n",
      "Delta bounds: [-0.322, 0.357]\n",
      "Oracle: 0.01164\n",
      "\n",
      "metric: m_a=1\n",
      "Standard bounds [-0.156, 0.195]\n",
      "Delta bounds: [-0.158, 0.195]\n",
      "Oracle: 0.01454\n",
      "\n",
      "metric: m_u\n",
      "Standard bounds [-0.317, 0.352]\n",
      "Delta bounds: [-0.156, 0.191]\n",
      "Oracle: 0.0138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'Y': Y, \n",
    "    'D': D, \n",
    "    'T': T\n",
    "}\n",
    "\n",
    "check_p_bounds(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5516a5c9",
   "metadata": {},
   "source": [
    "## Scratch stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "5a527715",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [456]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Making predictions and evaluating the model\u001b[39;00m\n\u001b[1;32m      8\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(XU)\n\u001b[0;32m----> 9\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m predictions\n",
      "File \u001b[0;32m~/.virtualenvs/10701-Project/lib/python3.9/site-packages/sklearn/metrics/_classification.py:211\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.virtualenvs/10701-Project/lib/python3.9/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "# Creating the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Fitting the model\n",
    "model.fit(XU, D)\n",
    "\n",
    "# Making predictions and evaluating the model\n",
    "predictions = model.predict_proba(XU)\n",
    "accuracy = accuracy_score(D, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "10701-Project",
   "language": "python",
   "name": "10701-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
