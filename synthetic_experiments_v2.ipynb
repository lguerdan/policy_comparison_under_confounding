{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "903a0e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from bound_funcs import *\n",
    "from utils import *\n",
    "from dgp import *\n",
    "\n",
    "\n",
    "\n",
    "def e1(dgp, XU, Z):\n",
    "    norm = 1/(2*np.sqrt(XU.shape[1]))\n",
    "    return sigmoid(norm * (( dgp['e1_coeffs'] * XU).sum(axis=1) + dgp['beta_zd'] * Z))\n",
    "\n",
    "def mu(dgp, coeffs, XU, Z, d):\n",
    "    \n",
    "    if d == 1:\n",
    "        coeffs = dgp[]\n",
    "    \n",
    "    norm = 1/(2*np.sqrt(XU.shape[1]))\n",
    "    return sigmoid(norm * ((coeffs * XU).sum(axis=1) + dgp['beta_zy'] * Z))\n",
    "\n",
    "def check_bounds(data, Vpf_down, Vpf_up):\n",
    "    '''Given observational data (Y,D,T) ~ p() compute bounds across measures of interest.'''\n",
    "\n",
    "    Y, D, T = data['Y'], data['D'], data['T']\n",
    "    v = np.zeros((2,2,2))\n",
    "\n",
    "    for y in range(2):\n",
    "        for d in range(2):\n",
    "            for t in range(2):\n",
    "                v[y,t,d] = ((Y==y) & (D==d) & (T==t)).mean()\n",
    "\n",
    "    metrics = ['m_y=1', 'm_y=0', 'm_a=0', 'm_a=1', 'm_u']\n",
    "    u = np.array([[1,0], [0, 1]])\n",
    "\n",
    "    for metric in metrics:\n",
    "\n",
    "        R_oracle = oracle_regret(v, u, metric)\n",
    "        Rs_down, Rs_up = standard_bounds(v, Vpf_down, Vpf_up, u, metric)\n",
    "        Rd_down, Rd_up = delta_bounds(v, Vpf_down, Vpf_up, u, metric)\n",
    "\n",
    "        print(f'metric: {metric}')\n",
    "        print(f'Standard bounds [{Rs_down:.3}, {Rs_up:.3}]')\n",
    "        print(f'Delta bounds: [{Rd_down:.3}, {Rd_up:.3}]')\n",
    "        print(f'Oracle: {R_oracle:.4}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d017412d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "70b61153",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dx, Du = 3, 10\n",
    "nD = Dx+Du\n",
    "\n",
    "# Measured and unmeasured covariate loadings\n",
    "e1_coeffs = 2*np.random.rand(nD) - 1\n",
    "z_coeffs = 2*np.random.rand(nD) - 1\n",
    "w_coeffs = 2*np.random.rand(nD) - 1\n",
    "mu1_coeffs = 2*np.random.rand(nD) - 1\n",
    "mu0_coeffs = 2*np.random.rand(nD) - 1\n",
    "\n",
    "\n",
    "\n",
    "dgp = {\n",
    "    'N': 5000,\n",
    "    'Dx': Dx,\n",
    "    'Du': Du,\n",
    "    'nz': 10,                # Number of finite pre-treatment values\n",
    "    'nw': 10,                # Number of finite post-treatment values\n",
    "    'beta_zd': 2,            # Z -> D loading (=0 ==> relevance is violated)\n",
    "    'beta_zy': 0,            # Z -> Y loading (=0 ==> exclusion restriction is satisfied)\n",
    "    'e1_coeffs': e1_coeffs,\n",
    "    'z_coeffs': z_coeffs,\n",
    "    'w_coeffs': w_coeffs,\n",
    "    'mu1_coeffs': mu1_coeffs,\n",
    "    'mu0_coeffs': mu0_coeffs,\n",
    "    'lambda': 2,\n",
    "    'assumption': 'MSM'\n",
    "}\n",
    "\n",
    "# Measured and unmeasured covariate loadings\n",
    "e1_coeffs = 2*np.random.rand(nD) - 1\n",
    "z_coeffs = 2*np.random.rand(nD) - 1\n",
    "w_coeffs = 2*np.random.rand(nD) - 1\n",
    "mu1_coeffs = 2*np.random.rand(nD) - 1\n",
    "mu0_coeffs = 2*np.random.rand(nD) - 1\n",
    "\n",
    "if dgp['assumption'] == 'MSM':\n",
    "    \n",
    "    dgp['lambda_star'] = np.random.uniform(1/dgp['lambda'], dgp['lambda'])\n",
    "    \n",
    "\n",
    "     \n",
    "    \n",
    "\n",
    "\n",
    "# Out here there should be some sort of DGP prep function that assigns the coeffs based on the causal assumptions.\n",
    "# Manipulating inside sampling function less clean\n",
    "\n",
    "dgp_assumption = 'TP'\n",
    "\n",
    "\n",
    "def generate_data(dgp):\n",
    "    \n",
    "    # Co-variate information\n",
    "    N, Dx, Du = dgp['N'], dgp['Dx'], dgp['Du']\n",
    "    nD = Dx+Du\n",
    "    \n",
    "    # Proxy information\n",
    "    nz, nw, beta_zd, beta_zy = dgp['nz'], dgp['nw'], dgp['beta_zd'], dgp['beta_zy']\n",
    "    \n",
    "    e1_coeffs = dgp['e1_coeffs']\n",
    "    z_coeffs = dgp['z_coeffs']\n",
    "    w_coeffs = dgp['w_coeffs']\n",
    "    mu1_coeffs = dgp['mu1_coeffs']\n",
    "    mu0_coeffs = dgp['mu0_coeffs']\n",
    "    \n",
    "    norm = 1/(2*np.sqrt(nD))\n",
    "    T = np.random.binomial(1,.35*np.ones(N))\n",
    "    \n",
    "    # Sample measured and unmeasured confounders\n",
    "    mean, cov = np.zeros(nD), np.eye(nD)\n",
    "    XU = np.random.multivariate_normal(mean, cov, N)\n",
    "\n",
    "    # Zero out these terms if the IV unconfoundedness assumption is satisfied\n",
    "    if dgp_assumption == 'IV':\n",
    "        print('zero z coefs')\n",
    "        z_coeffs[Dx:] = 0\n",
    "\n",
    "    # Compute the probability distribution for Z\n",
    "    prob_Z = np.exp(z_coeffs*XU)\n",
    "    prob_Z = prob_Z / np.sum(prob_Z.sum(axis=1))  \n",
    "    weights = np.random.rand(nD, nz)\n",
    "    logits = np.dot(XU, weights)\n",
    "    pZ = softmax(logits)\n",
    "\n",
    "    # Sample instrument values\n",
    "    Z = np.argmax(np.array([np.random.multinomial(1, p) for p in pZ]), axis=1)\n",
    "\n",
    "    # Treatment propensity is a function of X, U and Z. Beta is a scaling factor.    \n",
    "    pD = e1(dgp, XU, Z)\n",
    "    D = np.random.binomial(1, pD)\n",
    "\n",
    "    # Compute the probability distribution for W\n",
    "    # prob_W = np.exp(w_coeffs*XU)\n",
    "    # prob_W = prob_W / np.sum(prob_W.sum(axis=1))  \n",
    "    # weights = np.random.rand(nD, nW)\n",
    "    # logits = np.dot(XU, weights)\n",
    "    # pW = softmax(logits)\n",
    "    # W = np.argmax(np.array([np.random.multinomial(1, p) for p in pW]), axis=1)\n",
    "    \n",
    "    p_mu_1 = mu(dgp, dgp['mu1_coeffs'], XU, Z)\n",
    "    \n",
    "    if dgp['assumption'] == 'MSM':\n",
    "        p_mu_0 = dgp['lambda_star'] * p_mu_1\n",
    "    \n",
    "    else:\n",
    "        p_mu_0 = mu(dgp, dgp['mu0_coeffs'], XU, Z)\n",
    "    \n",
    "    p_mu = pD*p_mu_1 + (1-pD)*p_mu_0\n",
    "\n",
    "    Y = np.random.binomial(1, p_mu)\n",
    "\n",
    "\n",
    "    return {\n",
    "        'Y': Y,\n",
    "        'D': D,\n",
    "        'XU': XU,\n",
    "        'Z': Z,\n",
    "        'T': T\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fb05fb73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'N': 5000,\n",
       " 'Dx': 3,\n",
       " 'Du': 10,\n",
       " 'nz': 10,\n",
       " 'nw': 10,\n",
       " 'beta_zd': 2,\n",
       " 'beta_zy': 0,\n",
       " 'e1_coeffs': array([-0.38423103, -0.17080017,  0.39776127, -0.5226944 ,  0.1991525 ,\n",
       "         0.12916137, -0.97893472,  0.35488075, -0.28664397,  0.55518209,\n",
       "         0.0286428 ,  0.5341621 , -0.16682049]),\n",
       " 'z_coeffs': array([ 0.61138496,  0.96278481,  0.02573141,  0.83961893,  0.54028065,\n",
       "         0.39483237, -0.36924444,  0.35752086, -0.27201822,  0.73380494,\n",
       "         0.48690683, -0.6104928 , -0.63428146]),\n",
       " 'w_coeffs': array([-0.5181226 , -0.66281399, -0.78760784,  0.98166515,  0.56112596,\n",
       "        -0.44959156,  0.42939163, -0.8846204 , -0.39441318, -0.05480092,\n",
       "        -0.69466732,  0.98277214,  0.40163069]),\n",
       " 'mu1_coeffs': array([-0.15034936, -0.37835128,  0.1123084 ,  0.04581665, -0.38378139,\n",
       "         0.77823759, -0.37511603,  0.28701363, -0.9623329 ,  0.42259818,\n",
       "        -0.09581069, -0.2139295 , -0.69944138]),\n",
       " 'mu0_coeffs': array([ 0.73208493,  0.70935961,  0.41417304,  0.67018546,  0.37493797,\n",
       "         0.30835534,  0.199304  ,  0.4176296 , -0.13975484,  0.75879235,\n",
       "         0.44834071,  0.91266469,  0.22084568]),\n",
       " 'lambda': 2,\n",
       " 'assumption': 'MSM',\n",
       " 'lambda_star': 1.4153640259782096}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8ab9963f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric: m_y=1\n",
      "Standard bounds [-0.529, -0.294]\n",
      "Delta bounds: [-0.487, -0.339]\n",
      "Oracle: -0.4017\n",
      "\n",
      "metric: m_y=0\n",
      "Standard bounds [-0.513, -0.254]\n",
      "Delta bounds: [-0.466, -0.305]\n",
      "Oracle: -0.4357\n",
      "\n",
      "metric: m_a=0\n",
      "Standard bounds [-0.356, 0.189]\n",
      "Delta bounds: [-0.249, 0.0823]\n",
      "Oracle: 0.02611\n",
      "\n",
      "metric: m_a=1\n",
      "Standard bounds [-0.0441, 0.0644]\n",
      "Delta bounds: [-0.0441, 0.0644]\n",
      "Oracle: 0.01645\n",
      "\n",
      "metric: m_u\n",
      "Standard bounds [-0.148, 0.0669]\n",
      "Delta bounds: [-0.0773, -0.00393]\n",
      "Oracle: -0.025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# data = generate_data(dgp)\n",
    "\n",
    "# Vpf_down, Vpf_up = compute_iv_bounds(dgp, data)\n",
    "# check_bounds(data, Vpf_down, Vpf_up)\n",
    "# print()\n",
    "# Vpf_down, Vpf_up = compute_na_bounds(dgp, data)\n",
    "# check_bounds(data, Vpf_down, Vpf_up)\n",
    "# print()\n",
    "\n",
    "dgp['lambda'] = 1.5\n",
    "Vpf_down, Vpf_up = compute_msm_bounds(dgp, data)\n",
    "check_bounds(data, Vpf_down, Vpf_up)\n",
    "\n",
    "\n",
    "##### Note for next time working on this. \n",
    "###   To get the tc proxy ID to work, we need to be able to get different values of py for varying z's\n",
    "###   Need to be able to connect through U most likely\n",
    "#####\n",
    "# Vpf_down, Vpf_up = compute_tp_bounds(dgp, data)\n",
    "# check_bounds(data, Vpf_down, Vpf_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a73a42c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'lambda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [67]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Vpf_down, Vpf_up \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_msm_bounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdgp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m check_bounds(data, Vpf_down, Vpf_up)\n",
      "Input \u001b[0;32mIn [66]\u001b[0m, in \u001b[0;36mcompute_msm_bounds\u001b[0;34m(dgp, data)\u001b[0m\n\u001b[1;32m      3\u001b[0m XU, Z, T \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXU\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m p_mu_1 \u001b[38;5;241m=\u001b[39m mu(dgp, dgp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmu1_coeffs\u001b[39m\u001b[38;5;124m'\u001b[39m], XU, Z)\n\u001b[0;32m----> 6\u001b[0m mu_up \u001b[38;5;241m=\u001b[39m \u001b[43mdgp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlambda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m p_mu_1\n\u001b[1;32m      7\u001b[0m mu_down \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mdgp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlambda\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m*\u001b[39m p_mu_1\n\u001b[1;32m      9\u001b[0m v110_up \u001b[38;5;241m=\u001b[39m (T \u001b[38;5;241m*\u001b[39m mu_up \u001b[38;5;241m*\u001b[39m p_e0)\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[0;31mKeyError\u001b[0m: 'lambda'"
     ]
    }
   ],
   "source": [
    "Vpf_down, Vpf_up = compute_msm_bounds(dgp, data)\n",
    "check_bounds(data, Vpf_down, Vpf_up)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c3491ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_msm_bounds(dgp, data):\n",
    "    \n",
    "    XU, Z, T = data['XU'], data['Z'], data['T']\n",
    "    \n",
    "    p_mu_1 = mu(dgp, dgp['mu1_coeffs'], XU, Z)\n",
    "    mu_up = dgp['lambda'] * p_mu_1\n",
    "    mu_down = (1/dgp['lambda']) * p_mu_1\n",
    "    \n",
    "    v110_up = (T * mu_up * p_e0).mean()\n",
    "    v100_up = ((1-T) * mu_up * p_e0).mean()\n",
    "    v110_down = (T * mu_down * p_e0).mean()\n",
    "    v100_down = ((1-T) * mu_down * p_e0).mean()\n",
    "    \n",
    "    Vpf_down[0,1] = v110_down\n",
    "    Vpf_down[1,1] = v110_down\n",
    "    Vpf_down[0,0] = v100_down\n",
    "    Vpf_down[1,0] = v100_down\n",
    "\n",
    "    Vpf_up[0,1] = v110_up\n",
    "    Vpf_up[1,1] = v110_up\n",
    "    Vpf_up[0,0] = v100_up\n",
    "    Vpf_up[1,0] = v100_up \n",
    "    \n",
    "    return Vpf_down, Vpf_up\n",
    "\n",
    "    \n",
    "\n",
    "def compute_na_bounds(dgp, data):\n",
    "    \n",
    "    Y, D, T = data['Y'], data['D'], data['T']\n",
    "\n",
    "    Vpf_down, Vpf_up = np.zeros((2,2)), np.zeros((2,2))\n",
    "    \n",
    "    Vpf_up[0,1] = ((D==0) & (T==1)).mean()\n",
    "    Vpf_up[1,1] = ((D==0) & (T==1)).mean()\n",
    "    Vpf_up[0,0] = ((D==0) & (T==0)).mean()\n",
    "    Vpf_up[1,0] = ((D==0) & (T==0)).mean()\n",
    "    \n",
    "    return Vpf_down, Vpf_up\n",
    "\n",
    "\n",
    "def compute_tp_bounds(dgp, data):\n",
    "    XU, Z, T = data['XU'], data['Z'], data['T']\n",
    "\n",
    "    mu_z = np.zeros((dgp['nz'], dgp['N']))\n",
    "\n",
    "    p_e0 = 1 - e1(dgp, XU, Z)\n",
    "\n",
    "    # Compute upper and lower bounds on mu(a,x)\n",
    "    for z in range(dgp['nz']):\n",
    "\n",
    "        # Assert: This probability should vary across levels of z, \n",
    "        # even with exclusion restriction (beta_zy=0) satisfied\n",
    "        # This is because of the effects of confouners\n",
    "        mu_z[z] = mu(dgp, dgp['mu1_coeffs'], XU, z)\n",
    "\n",
    "\n",
    "    mu_down = mu_z.min(axis=0)\n",
    "    mu_up = mu_z.max(axis=0)\n",
    "\n",
    "    v110_up = (T * mu_up * p_e0).mean()\n",
    "    v100_up = ((1-T) * mu_up * p_e0).mean()\n",
    "    v110_down = (T * mu_down * p_e0).mean()\n",
    "    v100_down = ((1-T) * mu_down * p_e0).mean()\n",
    "\n",
    "    Vpf_down = np.zeros((2,2))\n",
    "    Vpf_up = np.zeros((2,2))\n",
    "\n",
    "    Vpf_down[0,1] = v110_down\n",
    "    Vpf_down[1,1] = v110_down\n",
    "    Vpf_down[0,0] = v100_down\n",
    "    Vpf_down[1,0] = v100_down\n",
    "\n",
    "    Vpf_up[0,1] = v110_up\n",
    "    Vpf_up[1,1] = v110_up\n",
    "    Vpf_up[0,0] = v100_up\n",
    "    Vpf_up[1,0] = v100_up \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def compute_iv_bounds(dgp, data):\n",
    "    \n",
    "    XU, Z, T = data['XU'], data['Z'], data['T']\n",
    "\n",
    "    mu_down_z = np.zeros((dgp['nz'], dgp['N']))\n",
    "    mu_up_z = np.zeros((dgp['nz'], dgp['N']))\n",
    "    \n",
    "    #TODO: here we are fitting functions based on unobservables so the U terms should be zeroed for e1, mu_1 \n",
    "    p_e1 = e1(dgp, XU, Z)\n",
    "    p_mu_1 = mu(dgp, dgp['mu1_coeffs'], XU, Z)\n",
    "\n",
    "    # Compute upper and lower bounds on mu(a,x)\n",
    "    for z in range(dgp['nz']):\n",
    "        e1_z =  e1(dgp, XU, z)\n",
    "        e0_z = 1-e1_z\n",
    "\n",
    "        mu_down_z[z] = e1_z*p_mu_1\n",
    "        mu_up_z[z] = e0_z + e1_z*p_mu_1\n",
    "\n",
    "    mu_down = mu_down_z.max(axis=0)\n",
    "    mu_up = mu_up_z.min(axis=0)\n",
    "    \n",
    "    v110_up = (T * (mu_up - p_mu_1 * p_e1)).mean()\n",
    "    v100_up = ((1-T) * (mu_up - p_mu_1 * p_e1)).mean()\n",
    "\n",
    "    v110_down = (T * (mu_down - p_mu_1 * p_e1)).mean()\n",
    "    v100_down = ((1-T) * (mu_down - p_mu_1 * p_e1)).mean()\n",
    "    \n",
    "    Vpf_down = np.zeros((2,2))\n",
    "    Vpf_up = np.zeros((2,2))\n",
    "    \n",
    "    Vpf_down[0,1] = v110_down\n",
    "    Vpf_down[1,1] = v110_down\n",
    "    Vpf_down[0,0] = v100_down\n",
    "    Vpf_down[1,0] = v100_down\n",
    "    \n",
    "    Vpf_up[0,1] = v110_up\n",
    "    Vpf_up[1,1] = v110_up\n",
    "    Vpf_up[0,0] = v100_up\n",
    "    Vpf_up[1,0] = v100_up  \n",
    "    \n",
    "    return Vpf_down, Vpf_up\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# Vpf_down = np.zeros((2,2))\n",
    "# Vpf_up = np.zeros((2,2))\n",
    "# v = np.zeros((2,2,2))\n",
    "\n",
    "# for y in range(2):\n",
    "#     for d in range(2):\n",
    "#         for t in range(2):\n",
    "#             v[y,t,d] = ((Y==y) & (D==d) & (T==t)).mean()\n",
    "\n",
    "\n",
    "# Vpf_up[0,1] = v110_up\n",
    "# Vpf_up[1,1] = v110_up\n",
    "# Vpf_up[0,0] = v100_up\n",
    "# Vpf_up[1,0] = v100_up            \n",
    "\n",
    "# Vpf_down[0,1] = v110_down\n",
    "# Vpf_down[1,1] = v110_down\n",
    "# Vpf_down[0,0] = v100_down\n",
    "# Vpf_down[1,0] = v100_down\n",
    "\n",
    "\n",
    "    \n",
    "# metrics = ['m_y=1', 'm_y=0', 'm_a=0', 'm_a=1', 'm_u']\n",
    "# u = np.array([[1,0], [0, 1]])\n",
    "\n",
    "# for metric in metrics:\n",
    "#     R_oracle = oracle_regret(v, u, metric)\n",
    "\n",
    "#     Rs_down, Rs_up = standard_bounds(v, Vpf_down, Vpf_up, u, metric)\n",
    "#     Rd_down, Rd_up = delta_bounds(v, Vpf_down, Vpf_up, u, metric)\n",
    "\n",
    "#     print(f'metric: {metric}')\n",
    "#     print(f'Standard bounds [{Rs_down:.3}, {Rs_up:.3}]')\n",
    "#     print(f'Delta bounds: [{Rd_down:.3}, {Rd_up:.3}]')\n",
    "#     print(f'Oracle: {R_oracle:.4}')\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99be303b",
   "metadata": {},
   "source": [
    "## Now, given these nuisance functions, we'd like to estimate Vpf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19d8505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b68a70a8",
   "metadata": {},
   "source": [
    "## Test computing bounds from the sampled joint distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03acaf5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mY\u001b[49m, \n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m: D, \n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m'\u001b[39m: T\n\u001b[1;32m      5\u001b[0m }\n\u001b[1;32m      7\u001b[0m check_p_bounds(data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y' is not defined"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'Y': Y, \n",
    "    'D': D, \n",
    "    'T': T\n",
    "}\n",
    "\n",
    "check_p_bounds(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5516a5c9",
   "metadata": {},
   "source": [
    "## Scratch stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a527715",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XU' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Fitting the model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mXU\u001b[49m, D)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Making predictions and evaluating the model\u001b[39;00m\n\u001b[1;32m      8\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(XU)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'XU' is not defined"
     ]
    }
   ],
   "source": [
    "# Creating the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Fitting the model\n",
    "model.fit(XU, D)\n",
    "\n",
    "# Making predictions and evaluating the model\n",
    "predictions = model.predict_proba(XU)\n",
    "accuracy = accuracy_score(D, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffc1641",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "10701-Project",
   "language": "python",
   "name": "10701-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
